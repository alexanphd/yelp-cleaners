{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b296baa2-de2a-4294-a656-1018c1020778",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298145f6-ef2d-4b7f-ae75-ddd3ab3662aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "this_directory = os.path.dirname(os.path.realpath('__file__')) # relative paths stopped working for some reason\n",
    "data_directory = this_directory + '/data/'\n",
    "processed_data_directory = data_directory + r'processed data' + '\\\\'\n",
    "model_directory = data_directory + r'models' + '\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ddb3ad-381b-4191-a82f-63085807cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer, HashingVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import Ridge, LinearRegression, SGDRegressor, LogisticRegression\n",
    "from sklearn import datasets, tree, utils\n",
    "from sklearn import model_selection, ensemble\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter, OrderedDict\n",
    "import math\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f540b0-0d3c-4fa2-b77e-f086c1b43e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yelpapi import YelpAPI\n",
    "# get yelp api key stored in txt file\n",
    "f = open(data_directory + 'yelp_api_key.txt','r')\n",
    "api_key = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3fb8ac-c09d-402f-b4fe-6374e91b85c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "STOP_WORDS = STOP_WORDS.union({'ll', 've'})\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292a4495-53c6-4292-84a9-cd21dee0c3a5",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9071e-de41-4a73-abc8-27ae6634655a",
   "metadata": {},
   "source": [
    "Trying a few new things beyond simple bag of words on individual reviews. Such a model is just not going to work because there are SO many reviews that don't mention cleanliness at all. I need to either weight reviews by how relevant they are to cleanliness, or better yet - don't train a model on irrelevant reviews. The key here is finding review \"relevance\" or a cleanliness sentiment for each review. This should be treated as an **unsupervised** problem, as the inspection scores only tell me about the overall cleanliness averaged over all reviews (within a certain time period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4974772b-9ed2-4d06-b039-b2a45b4cc1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(processed_data_directory + 'reviews_nearest_score_no_limit_df.csv')\n",
    "# df = pd.read_csv(processed_data_directory + 'reviews_nearest_score_2_years_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff26ff0-640f-4571-bd4d-855bf1a75957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>review_stars</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">-0TbQsmE2p1bhG30rgvK2Q</th>\n",
       "      <th>93.0</th>\n",
       "      <td>351</td>\n",
       "      <td>364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95.0</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98.0</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-4bP1UUgpZumIu6DZMaMzw</th>\n",
       "      <th>86.0</th>\n",
       "      <td>2233</td>\n",
       "      <td>2204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95.0</th>\n",
       "      <td>19</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zo-POOSRX0wiVJlJyvujyA</th>\n",
       "      <th>100.0</th>\n",
       "      <td>175</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">zr40jIjFDIcZ3dzbSK53Ww</th>\n",
       "      <th>84.0</th>\n",
       "      <td>54</td>\n",
       "      <td>52.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93.0</th>\n",
       "      <td>374</td>\n",
       "      <td>346.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zubXuwlAEbvZd-MiLOgofQ</th>\n",
       "      <th>100.0</th>\n",
       "      <td>773</td>\n",
       "      <td>787.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zvSUJ7J2-GcB-2E0W2ICbw</th>\n",
       "      <th>96.0</th>\n",
       "      <td>16</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6617 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              review_stars   stars\n",
       "business_id            Score                      \n",
       "-0TbQsmE2p1bhG30rgvK2Q 93.0            351   364.0\n",
       "                       95.0              5     4.0\n",
       "                       98.0              5     4.0\n",
       "-4bP1UUgpZumIu6DZMaMzw 86.0           2233  2204.0\n",
       "                       95.0             19    20.0\n",
       "...                                    ...     ...\n",
       "zo-POOSRX0wiVJlJyvujyA 100.0           175   164.0\n",
       "zr40jIjFDIcZ3dzbSK53Ww 84.0             54    52.5\n",
       "                       93.0            374   346.5\n",
       "zubXuwlAEbvZd-MiLOgofQ 100.0           773   787.5\n",
       "zvSUJ7J2-GcB-2E0W2ICbw 96.0             16    15.0\n",
       "\n",
       "[6617 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['business_id','Score']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a3e122b-248c-4452-8e17-83eef696b077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2506"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.business_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a42bf9-2ab5-4c6f-be88-eb7d3424983c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
